{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f24a3833",
   "metadata": {},
   "source": [
    "# Gaussian Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fedd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "def show_bgr(img, title=None):\n",
    "    if img is None:\n",
    "        raise ValueError('Image is None')\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.imshow(img_rgb)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_gray(img, title=None):\n",
    "    if img is None:\n",
    "        raise ValueError('Image is None')\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Set the image path (relative to the notebook). Change if needed.\n",
    "image_path = '1.jpeg'\n",
    "if not os.path.exists(image_path):\n",
    "    raise FileNotFoundError(f\"Image not found: {image_path}. Place your image in the notebook folder or update the path.\")\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    raise ValueError(f\"cv2.imread returned None for: {image_path}. Is it a valid image file?\")\n",
    "resized_image = cv2.resize(image, (1900, 800))\n",
    "resized_image_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(resized_image_rgb)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb98e11",
   "metadata": {},
   "source": [
    "# Median Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba42a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = cv2.medianBlur(resized_image, 11)\n",
    "median_rgb = cv2.cvtColor(median, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(median_rgb)\n",
    "plt.title('Median Blurred Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e151616f",
   "metadata": {},
   "source": [
    "# Bilateral Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38274fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilateral = cv2.bilateralFilter(resized_image, 15, 150, 150)\n",
    "bilateral_rgb = cv2.cvtColor(bilateral, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(bilateral_rgb)\n",
    "plt.title('Bilateral Blurred Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54731c65",
   "metadata": {},
   "source": [
    "# grayscaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('1.jpeg')\n",
    "if image is None:\n",
    "    raise FileNotFoundError('1.jpeg not found or unreadable')\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "show_gray(gray_image, 'Grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28344d27",
   "metadata": {},
   "source": [
    "# Weighted Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa35b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_weighted = cv2.imread('1.jpeg')\n",
    "if img_weighted is None:\n",
    "    raise FileNotFoundError('1.jpeg not found or unreadable')\n",
    "img_weighted = img_weighted.astype(float)\n",
    "rows, cols = img_weighted.shape[:2]\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        gray = 0.2989 * img_weighted[i, j, 2] + 0.5870 * img_weighted[i, j, 1] + 0.1140 * img_weighted[i, j, 0]\n",
    "        img_weighted[i, j] = [gray, gray, gray]\n",
    "img_weighted = np.clip(img_weighted, 0, 255).astype('uint8')\n",
    "show_bgr(img_weighted, 'Grayscale Image (Weighted)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ace41",
   "metadata": {},
   "source": [
    "# pixel manipulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b092e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('1.jpeg')\n",
    "if img is None:\n",
    "    raise FileNotFoundError('1.jpeg not found or unreadable')\n",
    "rows, cols = img.shape[:2]\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        gray = int((img[i, j, 0] + img[i, j, 1] + img[i, j, 2]) / 3)\n",
    "        img[i, j] = [gray, gray, gray]\n",
    "show_bgr(img, 'Grayscale Image (Average)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484761e",
   "metadata": {},
   "source": [
    "# Image Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04333883",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread('1.jpeg')\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "scale_factor_1 = 3.0  \n",
    "scale_factor_2 = 1/3.0\n",
    "height, width = image_rgb.shape[:2]\n",
    "new_height = int(height * scale_factor_1)\n",
    "new_width = int(width * scale_factor_1)\n",
    "\n",
    "zoomed_image = cv2.resize(src=image_rgb, \n",
    "                          dsize=(new_width, new_height), \n",
    "                          interpolation=cv2.INTER_CUBIC)\n",
    "new_height1 = int(height * scale_factor_2)\n",
    "new_width1 = int(width * scale_factor_2)\n",
    "scaled_image = cv2.resize(src= image_rgb, \n",
    "                          dsize =(new_width1, new_height1), \n",
    "                          interpolation=cv2.INTER_AREA)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "axs[0].imshow(image_rgb)\n",
    "axs[0].set_title('Original Image Shape:'+str(image_rgb.shape))\n",
    "axs[1].imshow(zoomed_image)\n",
    "axs[1].set_title('Zoomed Image Shape:'+str(zoomed_image.shape))\n",
    "axs[2].imshow(scaled_image)\n",
    "axs[2].set_title('Scaled Image Shape:'+str(scaled_image.shape))\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a9a71a",
   "metadata": {},
   "source": [
    "# Image Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd59d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('1.jpeg')\n",
    "image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "center = (image_rgb.shape[1] // 2, image_rgb.shape[0] // 2)\n",
    "angle = 30\n",
    "scale = 1\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "rotated_image = cv2.warpAffine(image_rgb, rotation_matrix, (img.shape[1], img.shape[0]))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7, 4))\n",
    "axs[0].imshow(image_rgb)\n",
    "axs[0].set_title('Original Image')\n",
    "axs[1].imshow(rotated_image)\n",
    "axs[1].set_title('Image Rotation')\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc7cfa",
   "metadata": {},
   "source": [
    "# Image Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('1.jpeg')\n",
    "image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "width, height = image_rgb.shape[1], image_rgb.shape[0]\n",
    "\n",
    "tx, ty = 100, 70\n",
    "translation_matrix = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)\n",
    "translated_image = cv2.warpAffine(image_rgb, translation_matrix, (width, height))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7, 4))\n",
    "axs[0].imshow(image_rgb), axs[0].set_title('Original Image')\n",
    "axs[1].imshow(translated_image), axs[1].set_title('Image Translation')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xticks([]), ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a10395",
   "metadata": {},
   "source": [
    "# Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31251fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('1.jpeg')\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "b, g, r = cv2.split(image_rgb)\n",
    "b_normalized = cv2.normalize(b.astype('float'), None, 0, 1, cv2.NORM_MINMAX)\n",
    "g_normalized = cv2.normalize(g.astype('float'), None, 0, 1, cv2.NORM_MINMAX)\n",
    "r_normalized = cv2.normalize(r.astype('float'), None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "normalized_image = cv2.merge((b_normalized, g_normalized, r_normalized))\n",
    "print(normalized_image[:, :, 0])\n",
    "\n",
    "plt.imshow(normalized_image)\n",
    "plt.xticks([]), \n",
    "plt.yticks([]), \n",
    "plt.title('Normalized Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a2b615",
   "metadata": {},
   "source": [
    "# Morphological Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d914420",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('1.jpeg')\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "dilated = cv2.dilate(image_gray, kernel, iterations=2)\n",
    "eroded = cv2.erode(image_gray, kernel, iterations=2)\n",
    "opening = cv2.morphologyEx(image_gray, cv2.MORPH_OPEN, kernel)\n",
    "closing = cv2.morphologyEx(image_gray, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(7, 7))\n",
    "axs[0, 0].imshow(dilated, cmap='Greys'), axs[0, 0].set_title('Dilated Image')\n",
    "axs[0, 1].imshow(eroded, cmap='Greys'), axs[0, 1].set_title('Eroded Image')\n",
    "axs[1, 0].imshow(opening, cmap='Greys'), axs[1, 0].set_title('Opening')\n",
    "axs[1, 1].imshow(closing, cmap='Greys'), axs[1, 1].set_title('Closing')\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xticks([]), ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cf37d",
   "metadata": {},
   "source": [
    "# Transformation Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659a5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('1.jpeg')\n",
    "c = 255/(np.log(1 + np.max(img)))\n",
    "log_transformed = c * np.log(1 + img)\n",
    "log_transformed = np.array(log_transformed, dtype = np.uint8)\n",
    "cv2.imwrite('log_transformed.jpg', log_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b20ef5",
   "metadata": {},
   "source": [
    " # Gamma Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b6ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('1.jpeg')\n",
    "for gamma in [0.1, 0.5, 1.2, 2.2]:\n",
    "    gamma_corrected = np.array(255*(img / 255) ** gamma, dtype = 'uint8')\n",
    "    cv2.imwrite('gamma_transformed'+str(gamma)+'.jpg', gamma_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb32c03",
   "metadata": {},
   "source": [
    "# Linear Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelVal(pix, r1, s1, r2, s2):\n",
    "    if (0 <= pix and pix <= r1):\n",
    "        return (s1 / r1)*pix\n",
    "    elif (r1 < pix and pix <= r2):\n",
    "        return ((s2 - s1)/(r2 - r1)) * (pix - r1) + s1\n",
    "    else:\n",
    "        return ((255 - s2)/(255 - r2)) * (pix - r2) + s2\n",
    "img = cv2.imread('1.jpeg')\n",
    "r1 = 70\n",
    "s1 = 0\n",
    "r2 = 140\n",
    "s2 = 255\n",
    "pixelVal_vec = np.vectorize(pixelVal)\n",
    "contrast_stretched = pixelVal_vec(img, r1, s1, r2, s2)\n",
    "cv2.imwrite('contrast_stretch.jpg', contrast_stretched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ed7aa",
   "metadata": {},
   "source": [
    "# Multiple Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = cv2.imread('1.jpeg')\n",
    "rows, cols, _ = img.shape\n",
    "\n",
    "M_left = np.float32([[1, 0, -50], [0, 1, 0]])\n",
    "M_right = np.float32([[1, 0, 50], [0, 1, 0]])\n",
    "M_top = np.float32([[1, 0, 0], [0, 1, 50]])\n",
    "M_bottom = np.float32([[1, 0, 0], [0, 1, -50]])\n",
    "\n",
    "img_left = cv2.warpAffine(img, M_left, (cols, rows))\n",
    "img_right = cv2.warpAffine(img, M_right, (cols, rows))\n",
    "img_top = cv2.warpAffine(img, M_top, (cols, rows))\n",
    "img_bottom = cv2.warpAffine(img, M_bottom, (cols, rows))\n",
    "\n",
    "plt.subplot(221), plt.imshow(img_left), plt.title('Left')\n",
    "plt.subplot(222), plt.imshow(img_right), plt.title('Right')\n",
    "plt.subplot(223), plt.imshow(img_top), plt.title('Top')\n",
    "plt.subplot(224), plt.imshow(img_bottom), plt.title('Bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c6356",
   "metadata": {},
   "source": [
    "# Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0d5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('1.jpeg')\n",
    "if image is None:\n",
    "    raise FileNotFoundError('1.jpeg not found or unreadable')\n",
    "height, width = image.shape[:2]\n",
    "quarter_height, quarter_width = height / 4, width / 4\n",
    "T = np.float32([[1, 0, quarter_width], [0, 1, quarter_height]])\n",
    "img_translation = cv2.warpAffine(image, T, (width, height))\n",
    "show_bgr(image, 'Original')\n",
    "show_bgr(img_translation, 'Translated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fa79f",
   "metadata": {},
   "source": [
    " # Pyramid Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191271cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('1.jpeg')\n",
    "if image is None:\n",
    "    raise FileNotFoundError('1.jpeg not found or unreadable')\n",
    "downsampled_image = cv2.pyrDown(image)\n",
    "show_bgr(image, 'Original')\n",
    "show_bgr(downsampled_image, 'Downsampled')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da168ea6",
   "metadata": {},
   "source": [
    "# Building a Gaussian Pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcfde40",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('1.jpeg')\n",
    "if image is None:\n",
    "    raise FileNotFoundError('1.jpeg not found or unreadable')\n",
    "pyramid = [image]\n",
    "for i in range(3):\n",
    "    image = cv2.pyrDown(image)\n",
    "    pyramid.append(image)\n",
    "for i in range(len(pyramid)-1, -1, -1):\n",
    "    print(f\"Pyramid Level {i}\")\n",
    "    show_bgr(pyramid[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b605eae4",
   "metadata": {},
   "source": [
    "# Convert BGR to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fde9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(r'1.jpeg')\n",
    "if src is None:\n",
    "    raise FileNotFoundError('1.jpeg not found or unreadable')\n",
    "gray_image = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "show_gray(gray_image, 'Grayscale Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2293d9af",
   "metadata": {},
   "source": [
    "# MakeBorder() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18cb93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"1.jpeg\")\n",
    "if image is None:\n",
    "    raise FileNotFoundError('1.jpeg not found or unreadable')\n",
    "image = cv2.copyMakeBorder(image, 10, 10, 10, 10, cv2.BORDER_CONSTANT, None, value = 0)\n",
    "show_bgr(image, 'With Border')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61caa3c9",
   "metadata": {},
   "source": [
    "# Border Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f124e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"1.jpeg\")\n",
    "if image is None:\n",
    "    raise FileNotFoundError('1.jpeg not found or unreadable')\n",
    "bordered_image_reflect = cv2.copyMakeBorder(image, 50, 50, 50, 50, cv2.BORDER_REFLECT)\n",
    "bordered_image_reflect_101 = cv2.copyMakeBorder(image, 50, 50, 50, 50, cv2.BORDER_REFLECT_101)\n",
    "bordered_image_replicate = cv2.copyMakeBorder(image, 50, 50, 50, 50, cv2.BORDER_REPLICATE)\n",
    "print(\"Border with Reflect\")\n",
    "show_bgr(bordered_image_reflect)\n",
    "print(\"Border with Reflect_101\")\n",
    "show_bgr(bordered_image_reflect_101)\n",
    "print(\"Border with Replicate\")\n",
    "show_bgr(bordered_image_replicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d71057",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa14dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('1.jpeg')\n",
    "if image is None:\n",
    "    raise FileNotFoundError('1.jpeg not found or unreadable')\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "def show_image(img, title):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "show_image(gray_image, 'Original Grayscale Image')\n",
    "_, thresh_binary = cv2.threshold(gray_image, 120, 255, cv2.THRESH_BINARY)\n",
    "show_image(thresh_binary, 'Binary Threshold')\n",
    "_, thresh_binary_inv = cv2.threshold(gray_image, 120, 255, cv2.THRESH_BINARY_INV)\n",
    "show_image(thresh_binary_inv, 'Binary Threshold Inverted')\n",
    "_, thresh_trunc = cv2.threshold(gray_image, 120, 255, cv2.THRESH_TRUNC)\n",
    "show_image(thresh_trunc, 'Truncated Threshold')\n",
    "_, thresh_tozero_inv = cv2.threshold(gray_image, 120, 255, cv2.THRESH_TOZERO_INV)\n",
    "show_image(thresh_tozero_inv, 'Set to 0 Inverted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce1c3c",
   "metadata": {},
   "source": [
    "# Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread('1.jpeg')\n",
    "if image is None:\n",
    "    raise FileNotFoundError('1.jpeg not found or unreadable')\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "def show_image(img, title):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "show_image(gray_image, \"Original Grayscale Image\")\n",
    "thresh_mean = cv2.adaptiveThreshold(\n",
    "    gray_image, 255,\n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    cv2.THRESH_BINARY,\n",
    "    199, 5\n",
    ")\n",
    "show_image(thresh_mean, \"Adaptive Mean Thresholding\")\n",
    "thresh_gauss = cv2.adaptiveThreshold(\n",
    "    gray_image, 255,\n",
    "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    cv2.THRESH_BINARY,\n",
    "    199, 5\n",
    ")\n",
    "show_image(thresh_gauss, \"Adaptive Gaussian Thresholding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8240d2",
   "metadata": {},
   "source": [
    "# Morphological operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded = files.upload()\n",
    "for file in uploaded.keys():\n",
    "    img = cv2.imdecode(np.frombuffer(\n",
    "        uploaded[file], np.uint8), cv2.IMREAD_COLOR)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "ret, thresh = cv2.threshold(\n",
    "    gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "kernel = np.ones((9, 9), np.uint8)\n",
    "closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "\n",
    "bg = cv2.dilate(closing, kernel, iterations=2)\n",
    "contours, _ = cv2.findContours(\n",
    "    closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "result = np.zeros(gray.shape, dtype=np.uint8)\n",
    "for contour in contours:\n",
    "    if cv2.contourArea(contour) > 1000:\n",
    "        cv2.fillPoly(result, [contour], 255)\n",
    "        kernel_open = np.ones((6, 6), np.uint8)\n",
    "opened_result = cv2.morphologyEx(\n",
    "    result, cv2.MORPH_OPEN, kernel_open, iterations=2)\n",
    "\n",
    "kernel_erode = np.ones((9, 9), np.uint8)\n",
    "final_result = cv2.erode(opened_result, kernel_erode, iterations=2)\n",
    "final_result = cv2.erode(opened_result, kernel_erode, iterations=2)\n",
    "plt.imshow(final_result, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e876213",
   "metadata": {},
   "source": [
    "# Feature Detection & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb4a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "img2 = cv2.imread('2.jpeg', cv2.IMREAD_COLOR)\n",
    "img = cv2.imread('2.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "_, threshold = cv2.threshold(img, 110, 255, cv2.THRESH_BINARY)\n",
    "contours, _ = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours:\n",
    "    approx = cv2.approxPolyDP(cnt, 0.009 * cv2.arcLength(cnt, True), True)\n",
    "    cv2.drawContours(img2, [approx], 0, (0, 0, 255), 5)\n",
    "    n = approx.ravel()\n",
    "    i = 0\n",
    "    for j in n:\n",
    "        if i % 2 == 0:  # x, y coords\n",
    "            x, y = n[i], n[i + 1]\n",
    "            coord = f\"{x} {y}\"\n",
    "            if i == 0:  # first point\n",
    "                cv2.putText(img2, \"Arrow tip\", (x, y), font, 0.5, (255, 0, 0))\n",
    "            else:\n",
    "                cv2.putText(img2, coord, (x, y), font, 0.5, (0, 255, 0))\n",
    "        i += 1\n",
    "\n",
    "# Show result\n",
    "cv2.imshow('Contours with Coordinates', img2)\n",
    "\n",
    "# Exit on 'q'\n",
    "if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7d09c",
   "metadata": {},
   "source": [
    "# image using Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = plt.imread('2.jpeg')  \n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153312a",
   "metadata": {},
   "source": [
    "# Histogram using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"2.jpeg\")\n",
    "g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "plt.subplot(121), plt.imshow(g, cmap='gray'), plt.axis(\"off\"), plt.title(\"Grayscale\")\n",
    "plt.subplot(122), plt.hist(g.ravel(),256,[0,256],color='k'), plt.title(\"Gray Histogram\")\n",
    "plt.show()\n",
    "for i,c in enumerate(('r','g','b')):\n",
    "    plt.plot(cv2.calcHist([img],[i],None,[256],[0,256]), color=c)\n",
    "plt.title(\"RGB Histograms\"), plt.xlabel(\"Intensity\"), plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294127d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('2.jpeg',0)\n",
    "plt.hist(img.ravel(),256,[0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('2.jpeg',0)\n",
    "\n",
    "histr = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "plt.plot(histr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee873c1e",
   "metadata": {},
   "source": [
    "# Erosion and Dilation of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ff776",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('2.jpeg', 0)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "img_erosion = cv2.erode(img, kernel, iterations=1)\n",
    "\n",
    "plt.imshow(img_erosion, cmap='gray')\n",
    "plt.title(\"After Erosion\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "\n",
    "plt.imshow(img_dilation, cmap='gray')\n",
    "plt.title(\"After Dilation\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa3e04f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
